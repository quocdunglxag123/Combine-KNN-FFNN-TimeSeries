{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5a2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import sqrt \n",
    "import time\n",
    "\n",
    "#Tien Xu Ly\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Draw Flot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cacuale error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#distance Libaray\n",
    "from dtw import dtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "#FFNN Libarary\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283ee4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc Dữ Liệu\n",
    "# @param   filePath     Đường dẫn tập dữ liệu CSV\n",
    "# @return  df           Tập dữ liệu csv dưới dạng df\n",
    "def readData(filePath):\n",
    "    # Load dữ liệu\n",
    "    dataCSV = pd.read_csv(filePath)\n",
    "    df=dataCSV[['Close']]\n",
    "    return df\n",
    "\n",
    "# Tiền Xử lý Dữ Liệu\n",
    "# @param  Data   Tập dữ liệu\n",
    "# @return df     Dữ liệu đã được tiền xử lý\n",
    "def cleanData(df):\n",
    "    # Replace null values with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "    # Remove outliers by replacing values outside of 10 standard deviations with the mean\n",
    "    std = df['Close'].std()\n",
    "    mean = df['Close'].mean()\n",
    "    df['Close'] = np.where(df['Close'] > (mean + 10*std), mean, df['Close'])\n",
    "    df['Close'] = np.where(df['Close'] < (mean - 10*std), mean, df['Close'])\n",
    "    # Scale data_AMZN to range [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n",
    "    # Fill in missing values with the mean of the previous and next values\n",
    "    df['Close'] = df['Close'].interpolate(method='linear')\n",
    "    return df\n",
    "\n",
    "# Chia dữ liệu thành train set và test set\n",
    "# @param  data                      Tập dữ liệu\n",
    "# @param  percentTrain              Tỷ lệ Tập train\n",
    "# @return train_data, test_data     Tập train và test   \n",
    "def splitData(data, percentTrain):\n",
    "    train_size = int(len(data) * (percentTrain/100))\n",
    "    train = data.iloc[:train_size, :]\n",
    "    test = data.iloc[train_size:, :]\n",
    "    return train, test\n",
    "\n",
    "# Xử lý dữ liệu thành dữ liệu đầu vào và đầu ra cho mô hình\n",
    "# @param      data            Dữ liệu cần chia cửa sổ\n",
    "# @param      size_window     Kích thước cửa sổ\n",
    "# @param      size_predict    Kích thước cửa sổ dự đoán\n",
    "# @param      stepWindow      số điểm dữ liệu trượt\n",
    "# @return     X, y            mảng cửa sổ mẫu và mảng điểm dự đoán tương ứng\n",
    "def prepare_data(data, size_window, size_predict, stepWindow):\n",
    "    X, y = [], []\n",
    "    startWindow = 0\n",
    "    for i in range(len(data) - size_window - 1):\n",
    "        if (len(data[(startWindow + size_window):(startWindow + size_window + size_predict) , 0]) != size_predict):\n",
    "            break\n",
    "        X.append(data[startWindow:(startWindow + size_window), :])\n",
    "        y.append(data[(startWindow + size_window):(startWindow + size_window + size_predict) , 0])\n",
    "        startWindow += stepWindow\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "#---------KNN-----------\n",
    "# Fucntion Tính khoảng cách giữa 2 chuỗi thời gian\n",
    "# @param    ts1            Chuỗi thứ nhất\n",
    "# @param    ts2            Chuỗi thứ hai\n",
    "# @return   euclidean      Khoảng cách euclidean    \n",
    "def euclidean_distance(ts1, ts2):\n",
    "    ts1= ts1.flatten()\n",
    "    ts2= ts2.flatten()\n",
    "    return euclidean(ts1,ts2)\n",
    "\n",
    "# Function lấy ra k chuỗi gần nhất\n",
    "# @param    k             Số lượng chuỗi gần nhất\n",
    "# @param    distanceArr   Mảng khoảng cách\n",
    "# @return   argsort       Vị trí chuỗi gần nhất        \n",
    "def kSimilarityTimeSeries(k, distanceArr):\n",
    "    distances = np.array(distanceArr)\n",
    "    return distances.argsort()[:k] \n",
    "\n",
    "# Tính khoảng cách DTW\n",
    "# @param    ts1            Chuỗi thứ nhất\n",
    "# @param    ts2            Chuỗi thứ hai\n",
    "# @return   euclidean      Khoảng cách euclidean  \n",
    "def dtw_dist(ts1, ts2):\n",
    "    dist, _, _, _ = dtw(ts1, ts2, dist=lambda ts1, ts2: np.abs(ts1 - ts2))\n",
    "    return dist\n",
    "\n",
    "# Thêm Dữ liệu\n",
    "# @param    X_train               Cửa sổ mẫu train\n",
    "# @param    y_train               Cửa sổ dự đoán train\n",
    "# @param    XTest                 Cửa sổ mẫu test\n",
    "# @param    yTest                 Cửa sổ dự đoán test\n",
    "# @return   X_train, y_train      Khoảng cách euclidean \n",
    "def toTrain(X_train, y_train, XTest, yTest):\n",
    "    X_train.append(XTest)\n",
    "    y_train.append(yTest)\n",
    "    return np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Dự đoán Euclidean\n",
    "# @param    nameData           Tên tập dữ liệu\n",
    "# @param    k                  Số lượng chuỗi gần nhất\n",
    "# @param    typeDistance       Độ đo sử dụng (Dtw, euclidean)\n",
    "# @param    X_train            Cửa sổ mẫu train\n",
    "# @param    y_train            Cửa sổ dự đoán train\n",
    "# @param    X_test             Cửa sổ mẫu test\n",
    "# @param    y_test             Cửa sổ dự đoán test\n",
    "# @return   y_pred_arr         Mảng dự đoán\n",
    "def predict_KNN(k, typeDistance, X_train, y_train, X_test, y_test):\n",
    "    y_pred_arr=[]\n",
    "    for iTest in range(len(X_test)):\n",
    "        if(k>len(X_train)):\n",
    "            k=len(X_train)\n",
    "        distanceArr=[]\n",
    "        for iTrain in range(len(X_train)-size_window+2):\n",
    "            if(typeDistance == 'Dtw'):\n",
    "                distance = dtw_dist(X_test[iTest],X_train[iTrain])\n",
    "            else:\n",
    "                distance = euclidean_distance(X_test[iTest],X_train[iTrain])\n",
    "            distanceArr.append(distance)\n",
    "        indexKNN= kSimilarityTimeSeries(k,distanceArr)\n",
    "        y_pred = np.mean(y_train[indexKNN])\n",
    "        y_pred_arr.append(y_pred)\n",
    "        X_train, y_train = toTrain(X_train.tolist(), y_train.tolist(),X_test[iTest].tolist(), y_test[iTest].tolist())\n",
    "        y_pred = np.array(y_pred_arr)\n",
    "   \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "#----------------FFNN--------------------------\n",
    "# Khởi tạo mô hình FFNN\n",
    "# @param    neuralInput         Kích thước Cửa sổ mẫu/ số neural lớp input\n",
    "# @param    num_layers_hidden   Số lượng lớp ẩn\n",
    "# @param    num_neural_hidden   Số neural lớp ẩn\n",
    "# @param    neuralOutput         Số neural lớp ouput\n",
    "# @return   model               Mô hình FFNN\n",
    "def create_model_FFNN(neuralInput, num_layers_hidden=1, neuralHidden=1, neuralOutput=1):\n",
    "    model = Sequential()\n",
    "    for i in range(num_layers_hidden):\n",
    "        if i == 0:\n",
    "            model.add(Dense(neuralHidden, input_dim= neuralInput, activation='sigmoid'))\n",
    "        else:\n",
    "            model.add(Dense(neuralHidden, activation='sigmoid'))\n",
    "    model.add(Dense(neuralOutput))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train FFNN \n",
    "# @param    nameData          Tên tập dữ liệu\n",
    "# @param    size_window       Kích thước Cửa sổ mẫu/ số neural lớp input\n",
    "# @param    X_train           cửa sổ mẫu tập train\n",
    "# @param    y_train           Cửa sổ dự đoán tập train\n",
    "# @param    neuralHidden      Số neural lớp ẩn\n",
    "# @param    numHiddenLayer    Số lớp ẩn\n",
    "# @param    size_predict      Kích thước Cửa sổ dự đoán/ Số neural lớp ouput\n",
    "# @return   best_params_FFNN  Tham số tốt nhất cho mô hình FFNN                \n",
    "def train_FFNN(nameData, typePredict, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict):\n",
    "    #param search\n",
    "    param_grid_FFNN = {'batch_size': [8, 16, 32, 64, 128],\n",
    "              'epochs': [50, 100, 150, 200, 250, 300],\n",
    "              'neuralHidden': [neuralHidden],\n",
    "              'num_layers_hidden' : [numHiddenLayer],\n",
    "              'neuralInput' : [size_window],\n",
    "              'neuralOutput' : [size_predict]}\n",
    "\n",
    "    # create the model\n",
    "    model_FFNN = KerasRegressor(build_fn=create_model_FFNN, verbose=0)\n",
    "    \n",
    "    # perform the grid search\n",
    "    grid_FFNN = GridSearchCV(estimator=model_FFNN, param_grid=param_grid_FFNN, cv=3)\n",
    "    grid_result_FFNN = grid_FFNN.fit(X_train, y_train)\n",
    "    \n",
    "    # train the model with the best parameters\n",
    "    best_params_FFNN = grid_result_FFNN.best_params_\n",
    "    \n",
    "    model_FFNN = create_model_FFNN( best_params_FFNN['neuralInput'], best_params_FFNN['num_layers_hidden'], best_params_FFNN['neuralHidden'],best_params_FFNN['neuralOutput'])\n",
    "    model_FFNN.fit(X_train, y_train, epochs=best_params_FFNN['epochs'], batch_size=best_params_FFNN['batch_size'], verbose=2, callbacks=[EarlyStopping(monitor='loss', patience=10)], shuffle=False)\n",
    "    \n",
    "    if(typePredict=='FFNN_Find_NeuralHidden'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NeuralHidden/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    else:\n",
    "        model_FFNN.save_weights('../BestParam/TuanTu/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    return best_params_FFNN\n",
    "\n",
    "\n",
    "\n",
    "# Train FFNN \n",
    "# @param    nameData          Tên tập dữ liệu\n",
    "# @param    size_window       Kích thước Cửa sổ mẫu/ số neural lớp input\n",
    "# @param    X_train           cửa sổ mẫu tập train\n",
    "# @param    y_train           Cửa sổ dự đoán tập train\n",
    "# @param    batchSize         Số lượng mẫu được đưa vào với mỗi lần lặp (epoch)\n",
    "# @param    epoch             Số lần lặp cập nhật trọng số\n",
    "# @param    neuralHidden      Số neural lớp ẩn\n",
    "# @param    numHiddenLayer    Số lớp ẩn\n",
    "# @param    size_predict      Kích thước Cửa sổ dự đoán/ Số neural lớp ouput\n",
    "# @return   best_params_FFNN  Tham số tốt nhất cho mô hình FFNN                \n",
    "def train_best_param_FFNN(nameData, typePredict, size_window, X_train, y_train, batchSize, epoch, neuralHidden, numHiddenLayer, size_predict):\n",
    "    #param search\n",
    "    param_grid_FFNN = {'batch_size': batchSize,\n",
    "              'epochs': epoch,\n",
    "              'neuralHidden': neuralHidden,\n",
    "              'num_layers_hidden' : numHiddenLayer,\n",
    "              'neuralInput' : size_window,\n",
    "              'neuralOutput' : size_predict}\n",
    "    \n",
    "    model_FFNN = create_model_FFNN( param_grid_FFNN['neuralInput'], param_grid_FFNN['num_layers_hidden'], param_grid_FFNN['neuralHidden'],param_grid_FFNN['neuralOutput'])\n",
    "    model_FFNN.fit(X_train, y_train, epochs=param_grid_FFNN['epochs'], batch_size=param_grid_FFNN['batch_size'], verbose=2, callbacks=[EarlyStopping(monitor='loss', patience=10)], shuffle=False)\n",
    "    \n",
    "    if(typePredict=='FFNN_Find_NeuralHidden'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NeuralHidden/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer'):\n",
    "        model_FFNN.save_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer_SongSong'):\n",
    "        model_FFNN.save_weights('../BestParam/SongSong/'+nameData+'/FFNN_Find_BestWeights/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    else:\n",
    "        model_FFNN.save_weights('../BestParam/TuanTu/'+nameData+'/FFNN_Find_BestWeights/'+str(int(param_grid_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(param_grid_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(param_grid_FFNN['batch_size']))+'_BatchSize_'+str(int(param_grid_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "   \n",
    "    return param_grid_FFNN\n",
    "\n",
    "# Dự Đoán FFNN \n",
    "# @param    nameData          Tên tập dữ liệu\n",
    "# @param    typePredict       Thực hiện loại dự đoán (FFNN_Find_NeuralHidden,FFNN_Find_NumberHiddenLayer,CombinePredict)\n",
    "# @param    X_train           cửa sổ mẫu tập train\n",
    "# @param    y_train           Cửa sổ dự đoán tập train\n",
    "# @param    X_test            Cửa sổ dự đoán tập train\n",
    "# @param    best_params_FFNN  Cửa sổ dự đoán tập train\n",
    "# @return   predictions_FFNN  Mảng dự đoán\n",
    "def predict_FFNN(nameData, typePredict, X_train, y_train, X_test, best_params_FFNN):\n",
    "    model_FFNN1 = Sequential()\n",
    "    for i in range(best_params_FFNN['num_layers_hidden']):\n",
    "        if i == 0:\n",
    "            model_FFNN1.add(Dense(best_params_FFNN['neuralHidden'], input_dim= best_params_FFNN['neuralInput'], activation='sigmoid'))\n",
    "        else:\n",
    "            model_FFNN1.add(Dense(best_params_FFNN['neuralHidden'], activation='sigmoid'))\n",
    "    model_FFNN1.add(Dense(best_params_FFNN['neuralOutput']))\n",
    "    \n",
    "    if(typePredict=='FFNN_Find_NeuralHidden'):\n",
    "        model_FFNN1.load_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NeuralHidden/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer'):\n",
    "        model_FFNN1.load_weights('../BestParam/FFNN/'+nameData+'/FFNN_Find_NumberHiddenLayer/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    elif (typePredict=='FFNN_Find_NumberHiddenLayer_SongSong'):\n",
    "        model_FFNN1.load_weights('../BestParam/SongSong/'+nameData+'/FFNN_Find_BestWeights/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "    else:\n",
    "        model_FFNN1.load_weights('../BestParam/TuanTu/'+nameData+'/FFNN_Find_BestWeights/'+str(int(best_params_FFNN['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_params_FFNN['neuralHidden']))+'_NeuralHidden_'+str(int(best_params_FFNN['batch_size']))+'_BatchSize_'+str(int(best_params_FFNN['epochs']))+'_Epoch_'+nameData+'.h5')   \n",
    "   \n",
    "    model_FFNN1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    predictions_FFNN = model_FFNN1.predict(X_test)\n",
    "    return predictions_FFNN\n",
    "\n",
    "#---------------------Song Song------------------------------#\n",
    "\n",
    "# Lai Ghép Song Song\n",
    "# @param    y_pred_FFNN     Mảng dự đoán của FFNN\n",
    "# @param    y_pred_KNN      Mảng dự đoán của KNN\n",
    "# @param    y_test          Mảng chuỗi thực tế\n",
    "# @return   y_pred_combine  Mảng dự đoán kết hợp\n",
    "def predictHybrid(y_pred_FFNN,y_pred_KNN,y_test):\n",
    "    FFNNSubKNN=[]\n",
    "    TestSubKNN=[]\n",
    "    weightEl=[]\n",
    "    for i in range(len(y_pred_FFNN)):\n",
    "        FFNNSubKNN.append(y_pred_FFNN[i]-y_pred_KNN[i])\n",
    "        TestSubKNN.append(y_test[i]-y_pred_KNN[i])\n",
    "\n",
    "    for j in range(len(FFNNSubKNN)):\n",
    "        weightEl.append(((FFNNSubKNN[j]*TestSubKNN[j])/ (FFNNSubKNN[j]*FFNNSubKNN[j])))\n",
    "    \n",
    "    weight = np.array(weightEl)\n",
    "    \n",
    "    y_pred_combine=[]\n",
    "    for i in range(len(weight)):\n",
    "        y_pred_combine.append(weight[i]*y_pred_FFNN[i]+(1-weight[i])*y_pred_KNN[i])\n",
    "    y_pred_combine=np.array(y_pred_combine)\n",
    "    return y_pred_combine\n",
    "\n",
    "#---------------------Tuần Tự------------------------------#\n",
    "\n",
    "# Tính Lỗi Theo Từng Ngày\n",
    "# @param    y_pred_KNN      Mảng dự đoán của KNN\n",
    "# @param    y_test          Mảng chuỗi thực tế\n",
    "# @return   mseWithDay     Mảng lỗi theo ngày\n",
    "def mseWithDay(y_pred_KNN, y_test):\n",
    "    mseDay = []\n",
    "    for i in range(len(y_pred_KNN)):\n",
    "        mseDay.append([abs((y_test[i] - y_pred_KNN[i]))])\n",
    "    mseDay=np.array(mseDay)\n",
    "    return mseDay\n",
    "\n",
    "def predictSum(y_pred_mse,y_pred_KNN):\n",
    "    pred_knn_ffnn=[]\n",
    "    for i in range(len(y_pred_mse)):\n",
    "        pred_knn_ffnn.append(y_pred_KNN[i]+y_pred_mse[i])\n",
    "    pred_knn_ffnn=np.array(pred_knn_ffnn)\n",
    "    return pred_knn_ffnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c5e5b",
   "metadata": {},
   "source": [
    "# Đánh Giá Ảnh Hưởng Tỷ Lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef68d35f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVALTỷ Lệ 80 20 Best Param: 1_HiddenLayer_13_NeuralHidden_8_BatchSize_200_Epoch_3290.6626110076904_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'AVAL'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+'Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9a1312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVAL Tỷ Lệ 70 30 Best Param: 1_HiddenLayer_19_NeuralHidden_16_BatchSize_200_Epoch_3137.622344493866_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'AVAL'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 70\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 70 30 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f2e7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGLE Tỷ Lệ 80 20 Best Param: 1_HiddenLayer_19_NeuralHidden_8_BatchSize_300_Epoch_4550.312443494797_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'AGLE'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87420e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGLE Tỷ Lệ 70 30 Best Param: 1_HiddenLayer_20_NeuralHidden_8_BatchSize_250_Epoch_3153.6635518074036_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'AGLE'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 70\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 70 30 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ffeb487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDLY Tỷ Lệ 80 20 Best Param: 1_HiddenLayer_19_NeuralHidden_8_BatchSize_300_Epoch_6084.028868198395_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'MDLY'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65145c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDLY Tỷ Lệ 70 30 Best Param: 1_HiddenLayer_20_NeuralHidden_8_BatchSize_300_Epoch_6259.933722257614_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'MDLY'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 70\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 70 30 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57d39459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDDY Tỷ Lệ 80 20 Best Param: 1_HiddenLayer_20_NeuralHidden_8_BatchSize_300_Epoch_6444.700438976288_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'GDDY'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8badd554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDDY Tỷ Lệ 70 30 Best Param: 1_HiddenLayer_14_NeuralHidden_8_BatchSize_300_Epoch_5600.134698867798_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'GDDY'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 70\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numHiddenLayer=[1]\n",
    "start_Train= time.time()\n",
    "best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, numHiddenLayer, size_predict)\n",
    "end_Train = time.time()\n",
    "print(nameData+' Tỷ Lệ 70 30 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00daa4",
   "metadata": {},
   "source": [
    "# Đánh Giá Ảnh Hưởng Số Lượng Lớp Ẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f24f27a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AVALTỷ Lệ 80 20 Best Param: 1_HiddenLayer_16_NeuralHidden_8_BatchSize_250_Epoch_4990.134747982025_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AVALTỷ Lệ 80 20 Best Param: 2_HiddenLayer_16_NeuralHidden_16_BatchSize_300_Epoch_4862.012566566467_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AVALTỷ Lệ 80 20 Best Param: 3_HiddenLayer_20_NeuralHidden_16_BatchSize_300_Epoch_4235.796914339066_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AVALTỷ Lệ 80 20 Best Param: 4_HiddenLayer_20_NeuralHidden_16_BatchSize_300_Epoch_3974.2578916549683_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AVALTỷ Lệ 80 20 Best Param: 5_HiddenLayer_19_NeuralHidden_8_BatchSize_250_Epoch_4185.7427361011505_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'AVAL'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "for i in range(1,6):\n",
    "    start_Train= time.time()\n",
    "    best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, [i], size_predict)\n",
    "    end_Train = time.time()\n",
    "    print('Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn '+nameData+'Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf4c413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AGLETỷ Lệ 80 20 Best Param: 1_HiddenLayer_15_NeuralHidden_8_BatchSize_300_Epoch_3513.624835729599_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AGLETỷ Lệ 80 20 Best Param: 2_HiddenLayer_20_NeuralHidden_8_BatchSize_250_Epoch_4393.595132112503_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AGLETỷ Lệ 80 20 Best Param: 3_HiddenLayer_19_NeuralHidden_8_BatchSize_200_Epoch_4580.063223361969_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AGLETỷ Lệ 80 20 Best Param: 4_HiddenLayer_15_NeuralHidden_8_BatchSize_250_Epoch_4115.2406713962555_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn AGLETỷ Lệ 80 20 Best Param: 5_HiddenLayer_18_NeuralHidden_8_BatchSize_250_Epoch_4338.5587430000305_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'AGLE'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "for i in range(1,6):\n",
    "    start_Train= time.time()\n",
    "    best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, [i], size_predict)\n",
    "    end_Train = time.time()\n",
    "    print('Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn '+nameData+'Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f0afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn MDLYTỷ Lệ 80 20 Best Param: 1_HiddenLayer_19_NeuralHidden_8_BatchSize_300_Epoch_8003.195628404617_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn MDLYTỷ Lệ 80 20 Best Param: 2_HiddenLayer_16_NeuralHidden_8_BatchSize_300_Epoch_3923.034392595291_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn MDLYTỷ Lệ 80 20 Best Param: 3_HiddenLayer_16_NeuralHidden_8_BatchSize_300_Epoch_4312.10093832016_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn MDLYTỷ Lệ 80 20 Best Param: 4_HiddenLayer_20_NeuralHidden_8_BatchSize_250_Epoch_4850.220484256744_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn MDLYTỷ Lệ 80 20 Best Param: 5_HiddenLayer_16_NeuralHidden_8_BatchSize_300_Epoch_5803.882265329361_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'MDLY'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "for i in range(1,6):\n",
    "    start_Train= time.time()\n",
    "    best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, [i], size_predict)\n",
    "    end_Train = time.time()\n",
    "    print('Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn '+nameData+'Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72002c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn GDDYTỷ Lệ 80 20 Best Param: 1_HiddenLayer_18_NeuralHidden_8_BatchSize_300_Epoch_3695.619271993637_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn GDDYTỷ Lệ 80 20 Best Param: 2_HiddenLayer_19_NeuralHidden_8_BatchSize_250_Epoch_4406.43390417099_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn GDDYTỷ Lệ 80 20 Best Param: 3_HiddenLayer_15_NeuralHidden_16_BatchSize_300_Epoch_4967.507395505905_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn GDDYTỷ Lệ 80 20 Best Param: 4_HiddenLayer_20_NeuralHidden_8_BatchSize_300_Epoch_5935.304007053375_Time\n",
      "Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn GDDYTỷ Lệ 80 20 Best Param: 5_HiddenLayer_19_NeuralHidden_8_BatchSize_250_Epoch_7014.6119837760925_Time\n"
     ]
    }
   ],
   "source": [
    "nameData= 'GDDY'\n",
    "filePath= '../../Dataset/'+nameData+'.csv'\n",
    "timeSeries = readData(filePath)\n",
    "timeSeries = cleanData(timeSeries)\n",
    "percentTrain = 80\n",
    "train_data, test_data = splitData(timeSeries, percentTrain)\n",
    "size_window = 7\n",
    "size_predict=1\n",
    "stepWindow=1\n",
    "X_train, y_train = prepare_data(train_data.values, size_window, size_predict, stepWindow)\n",
    "X_test, y_test =   prepare_data(test_data.values, size_window, size_predict, stepWindow)\n",
    "neuralHidden=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "for i in range(1,6):\n",
    "    start_Train= time.time()\n",
    "    best_param = train_FFNN_not_save(nameData, size_window, X_train, y_train, neuralHidden, [i], size_predict)\n",
    "    end_Train = time.time()\n",
    "    print('Đánh Giá Ảnh Hưởng Của Số Lượng Lớp Ẩn '+nameData+'Tỷ Lệ 80 20 Best Param: '+str(int(best_param['num_layers_hidden']))+'_HiddenLayer_'+str(int(best_param['neuralHidden']))+'_NeuralHidden_'+str(int(best_param['batch_size']))+'_BatchSize_'+str(int(best_param['epochs']))+'_Epoch_' + str(end_Train-start_Train)+'_Time')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387b0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfae56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80801c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
